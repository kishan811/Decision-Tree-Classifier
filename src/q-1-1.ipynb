{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import math\n",
    "from math import log\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making decision tree class (Display to show build tree)\n",
    "### Predict function is used to predict label of test data given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Make_Dec_Tree:\n",
    "    def __init__(self, colss):\n",
    "        x = colss\n",
    "        self.colss = x\n",
    "        self.leaf = {}\n",
    "    def pre(self, x):\n",
    "        if not self.leaf == {}: # reached leaf level\n",
    "            if x[self.colss] in self.leaf:\n",
    "                s = self.leaf[x[self.colss]]\n",
    "                return s.pre(x)\n",
    "        else:\n",
    "            return self.colss\n",
    "\n",
    "    def display(self, level = 0):\n",
    "        if not self.leaf == {}:\n",
    "            for x in self.leaf.keys():\n",
    "                p = \"\\n\" + \" \" * level * 4\n",
    "                print(p, self.colss, \"=\", x,end=\"\")\n",
    "                self.leaf[x].display(level + 1)\n",
    "        else:\n",
    "            print(\": \", self.colss, end=\"\")\n",
    "     \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculation of entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropyfn(df, label):\n",
    "    df=df.values\n",
    "    label_column = df[:, -1]\n",
    "    _, counts = np.unique(label_column, return_counts=True)\n",
    "    q_value = counts / counts.sum()\n",
    "    entropy = sum(q_value * -np.log2(q_value))\n",
    "    return entropy\n",
    "\n",
    "# def InfoGain(data,split_attribute_name,label_name=\"class\"):\n",
    "#     total_entropy = entropyfn(data[label_name])\n",
    "#     vals,counts= np.unique(data[split_attribute_name],return_counts=True)\n",
    "#     Weighted_Entropy = np.sum([(counts[i]/np.sum(counts))*entropyfn(data.where(data[split_attribute_name]==vals[i]).dropna()[label_name]) for i in range(len(vals))])\n",
    "#     Information_Gain = total_entropy - Weighted_Entropy\n",
    "#     return Information_Gain\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing attribute with max info gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_best_Attribute(df, label, attributes):\n",
    "    TL = len(df)\n",
    "    info_gain = []\n",
    "    baseEntropy = entropyfn(df, label)\n",
    "    for x in attributes:\n",
    "        weighted_entr = 0\n",
    "        selected_attr_list = df.groupby(x)\n",
    "        for key,temp in selected_attr_list:\n",
    "            del temp[x]\n",
    "            xtl = len(temp)\n",
    "            lkte = (xtl / TL)\n",
    "            weighted_entr += lkte*entropyfn(temp,label)\n",
    "        totent = baseEntropy-weighted_entr\n",
    "        info_gain.append([x,totent])\n",
    "    bestAttribute = max(info_gain, key=lambda x: x[1])\n",
    "    return(bestAttribute[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_sklearn():\n",
    "    #Comparing result with in-built(scikit-learn) decision tree function to check correctness of algorithm used\n",
    "    df = pd.read_csv(\"../input_data/train1.csv\")\n",
    "    from sklearn import tree\n",
    "    model = tree.DecisionTreeClassifier()\n",
    "    le_salary = LabelEncoder()\n",
    "    le_sales=LabelEncoder()\n",
    "    df['sales_n'] = le_salary.fit_transform(df['sales'])\n",
    "    df['salary_n'] = le_sales.fit_transform(df['salary'])\n",
    "    df=df.drop(['sales','salary'],axis='columns')\n",
    "    df=df.drop([\"satisfaction_level\",\"last_evaluation\",\"number_project\",\"average_montly_hours\",\"time_spend_company\"],axis='columns')\n",
    "    #dividing the data into training and testing data(for validation)\n",
    "    msk = np.random.rand(len(df)) < 0.8\n",
    "    train2 = df[msk]\n",
    "    test2 = df[~msk]\n",
    "    trainy=train2['left']\n",
    "    trainx=train2.drop(['left'],axis='columns')\n",
    "\n",
    "    #training the model\n",
    "    model.fit(trainx,trainy)\n",
    "    testy=test2['left']\n",
    "    testx=test2.drop(['left'],axis='columns')\n",
    "\n",
    "    #predicting over the test data\n",
    "    pred=model.predict(testx)\n",
    "    print( accuracy_score(testy,pred))\n",
    "    print (confusion_matrix(testy,pred))\n",
    "    print (classification_report(testy,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Decision_tree_algo(df, label, attributes1):\n",
    "    attributes=attributes1[:]\n",
    "    u_val = df.apply(lambda x: x.nunique()).loc[label]\n",
    "    if u_val==1:\n",
    "        return Make_Dec_Tree(df[label].iloc[0])\n",
    "    if len(attributes) == 0:\n",
    "        item_counts = df[label].value_counts()\n",
    "        max_item = item_counts.idxmax()\n",
    "        return Make_Dec_Tree(max_item)\n",
    "    \n",
    "    bestAttribute = choose_best_Attribute(df, label, attributes)\n",
    "    # print(bestAttribute)\n",
    "    attributes.remove(bestAttribute)\n",
    "    selected_attr_list = df.groupby(bestAttribute)\n",
    "    root_attr = Make_Dec_Tree(bestAttribute)\n",
    "    \n",
    "    for key,temp in selected_attr_list:\n",
    "        if not len(temp) == 0:\n",
    "            root_attr.leaf[key] = Decision_tree_algo(temp.drop([bestAttribute],axis=1), label, attributes)\n",
    "        else:\n",
    "            item_counts = temp[label].value_counts()\n",
    "            max_item = item_counts.idxmax()\n",
    "            root_attr.leaf[key] = Make_Dec_Tree(max_item)\n",
    "\n",
    "    return root_attr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " salary = high\n",
      "     sales = IT\n",
      "         Work_accident = 0\n",
      "             promotion_last_5years = 0:  0\n",
      "         Work_accident = 1:  0\n",
      "     sales = RandD:  0\n",
      "     sales = accounting\n",
      "         Work_accident = 0\n",
      "             promotion_last_5years = 0:  0\n",
      "             promotion_last_5years = 1:  0\n",
      "         Work_accident = 1:  0\n",
      "     sales = hr\n",
      "         Work_accident = 0\n",
      "             promotion_last_5years = 0:  0\n",
      "         Work_accident = 1:  0\n",
      "     sales = management\n",
      "         promotion_last_5years = 0\n",
      "             Work_accident = 0:  0\n",
      "             Work_accident = 1:  0\n",
      "         promotion_last_5years = 1:  0\n",
      "     sales = marketing\n",
      "         Work_accident = 0\n",
      "             promotion_last_5years = 0:  0\n",
      "             promotion_last_5years = 1:  0\n",
      "         Work_accident = 1:  0\n",
      "     sales = product_mng\n",
      "         Work_accident = 0\n",
      "             promotion_last_5years = 0:  0\n",
      "         Work_accident = 1:  0\n",
      "     sales = sales\n",
      "         Work_accident = 0\n",
      "             promotion_last_5years = 0:  0\n",
      "             promotion_last_5years = 1:  0\n",
      "         Work_accident = 1:  0\n",
      "     sales = support\n",
      "         Work_accident = 0\n",
      "             promotion_last_5years = 0:  0\n",
      "         Work_accident = 1:  0\n",
      "     sales = technical\n",
      "         Work_accident = 0\n",
      "             promotion_last_5years = 0:  0\n",
      "         Work_accident = 1:  0\n",
      " salary = low\n",
      "     Work_accident = 0\n",
      "         sales = IT\n",
      "             promotion_last_5years = 0:  0\n",
      "             promotion_last_5years = 1:  1\n",
      "         sales = RandD\n",
      "             promotion_last_5years = 0:  0\n",
      "             promotion_last_5years = 1:  0\n",
      "         sales = accounting\n",
      "             promotion_last_5years = 0:  0\n",
      "         sales = hr\n",
      "             promotion_last_5years = 0:  0\n",
      "             promotion_last_5years = 1:  0\n",
      "         sales = management\n",
      "             promotion_last_5years = 0:  0\n",
      "             promotion_last_5years = 1:  1\n",
      "         sales = marketing\n",
      "             promotion_last_5years = 0:  0\n",
      "             promotion_last_5years = 1:  0\n",
      "         sales = product_mng\n",
      "             promotion_last_5years = 0:  0\n",
      "         sales = sales\n",
      "             promotion_last_5years = 0:  0\n",
      "             promotion_last_5years = 1:  0\n",
      "         sales = support\n",
      "             promotion_last_5years = 0:  0\n",
      "             promotion_last_5years = 1:  0\n",
      "         sales = technical\n",
      "             promotion_last_5years = 0:  0\n",
      "             promotion_last_5years = 1:  0\n",
      "     Work_accident = 1\n",
      "         sales = IT\n",
      "             promotion_last_5years = 0:  0\n",
      "         sales = RandD\n",
      "             promotion_last_5years = 0:  0\n",
      "             promotion_last_5years = 1:  0\n",
      "         sales = accounting\n",
      "             promotion_last_5years = 0:  0\n",
      "         sales = hr\n",
      "             promotion_last_5years = 0:  0\n",
      "         sales = management\n",
      "             promotion_last_5years = 0:  0\n",
      "             promotion_last_5years = 1:  0\n",
      "         sales = marketing\n",
      "             promotion_last_5years = 0:  0\n",
      "             promotion_last_5years = 1:  0\n",
      "         sales = product_mng\n",
      "             promotion_last_5years = 0:  0\n",
      "         sales = sales\n",
      "             promotion_last_5years = 0:  0\n",
      "             promotion_last_5years = 1:  1\n",
      "         sales = support\n",
      "             promotion_last_5years = 0:  0\n",
      "         sales = technical\n",
      "             promotion_last_5years = 0:  0\n",
      "             promotion_last_5years = 1:  0\n",
      " salary = medium\n",
      "     Work_accident = 0\n",
      "         sales = IT\n",
      "             promotion_last_5years = 0:  0\n",
      "             promotion_last_5years = 1:  1\n",
      "         sales = RandD\n",
      "             promotion_last_5years = 0:  0\n",
      "             promotion_last_5years = 1:  0\n",
      "         sales = accounting\n",
      "             promotion_last_5years = 0:  0\n",
      "             promotion_last_5years = 1:  0\n",
      "         sales = hr\n",
      "             promotion_last_5years = 0:  0\n",
      "             promotion_last_5years = 1:  0\n",
      "         sales = management\n",
      "             promotion_last_5years = 0:  0\n",
      "             promotion_last_5years = 1:  0\n",
      "         sales = marketing\n",
      "             promotion_last_5years = 0:  0\n",
      "             promotion_last_5years = 1:  0\n",
      "         sales = product_mng\n",
      "             promotion_last_5years = 0:  0\n",
      "         sales = sales\n",
      "             promotion_last_5years = 0:  0\n",
      "             promotion_last_5years = 1:  0\n",
      "         sales = support\n",
      "             promotion_last_5years = 0:  0\n",
      "             promotion_last_5years = 1:  0\n",
      "         sales = technical\n",
      "             promotion_last_5years = 0:  0\n",
      "             promotion_last_5years = 1:  0\n",
      "     Work_accident = 1\n",
      "         sales = IT:  0\n",
      "         sales = RandD\n",
      "             promotion_last_5years = 0:  0\n",
      "             promotion_last_5years = 1:  0\n",
      "         sales = accounting\n",
      "             promotion_last_5years = 0:  0\n",
      "         sales = hr\n",
      "             promotion_last_5years = 0:  0\n",
      "             promotion_last_5years = 1:  0\n",
      "         sales = management\n",
      "             promotion_last_5years = 0:  0\n",
      "             promotion_last_5years = 1:  0\n",
      "         sales = marketing\n",
      "             promotion_last_5years = 0:  0\n",
      "             promotion_last_5years = 1:  0\n",
      "         sales = product_mng\n",
      "             promotion_last_5years = 0:  0\n",
      "         sales = sales\n",
      "             promotion_last_5years = 0:  0\n",
      "             promotion_last_5years = 1:  0\n",
      "         sales = support\n",
      "             promotion_last_5years = 0:  0\n",
      "             promotion_last_5years = 1:  0\n",
      "         sales = technical\n",
      "             promotion_last_5years = 0:  0\n",
      "             promotion_last_5years = 1:  0\n",
      "The accuracy is:  0.7597864768683275\n",
      "\n",
      "Recall:  0.0018552875695732839\n",
      "\n",
      "Precision:  1.0\n",
      "\n",
      "F1-Score:  0.003703703703703704\n",
      "\n",
      "True pos:  1\n",
      "\n",
      "False pos:  0\n",
      "\n",
      "True neg:  1707\n",
      "\n",
      "False neg:  538\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('../input_data/train1.csv')\n",
    "train, test = train_test_split(train, test_size = 0.2)\n",
    "# label = sys.argv[1]\n",
    "label = \"left\"\n",
    "\n",
    "attributes = train.columns.tolist()\n",
    "x = [\"satisfaction_level\",\"last_evaluation\",\"number_project\",\"average_montly_hours\",\"time_spend_company\"]\n",
    "for i in x:\n",
    "    attributes.remove(i)\n",
    "attributes.remove(label)\n",
    "# while True:\n",
    "#         try:\n",
    "#             word_list.remove(vowel)\n",
    "#         except:\n",
    "#             break\n",
    "test = test.reset_index()\n",
    "tree = Decision_tree_algo(train,label,attributes)\n",
    "tree.display()\n",
    "# print(bestAttribute)\n",
    "# print(bestAttribute)\n",
    "\n",
    "tp,fp,tn,fn=0,0,0,0\n",
    "correct = 0\n",
    "for i in range(0,len(test)):\n",
    "    if tree.pre(test.loc[i])==1 and test.loc[i,label]==1:\n",
    "        tp+=1\n",
    "    if tree.pre(test.loc[i])==1 and test.loc[i,label]==0:\n",
    "        fp+=1\n",
    "    if tree.pre(test.loc[i])==0 and test.loc[i,label]==0:\n",
    "        tn+=1\n",
    "    if tree.pre(test.loc[i])==0 and test.loc[i,label]==1:\n",
    "        fn+=1\n",
    "    if str(tree.pre(test.loc[i])) == str(test.loc[i,label]):\n",
    "        correct += 1\n",
    "\n",
    "print(\"\\nThe accuracy is: \", correct/len(test))\n",
    "y = (tp+fp)\n",
    "x = (tp+fn)\n",
    "if x:\n",
    "    rc=tp/x\n",
    "if y:\n",
    "    pc=tp/y\n",
    "if (rc+pc):\n",
    "    f1=(2*rc*pc)/(rc+pc)\n",
    "print(\"\\nRecall: \", rc)\n",
    "print(\"\\nPrecision: \", pc)\n",
    "print(\"\\nF1-Score: \", f1)\n",
    "\n",
    "print(\"\\nTrue pos: \",tp)\n",
    "print(\"\\nFalse pos: \",fp)\n",
    "print(\"\\nTrue neg: \",tn)\n",
    "print(\"\\nFalse neg: \",fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7490892531876139\n",
      "[[1645    0]\n",
      " [ 551    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      1.00      0.86      1645\n",
      "           1       0.00      0.00      0.00       551\n",
      "\n",
      "   micro avg       0.75      0.75      0.75      2196\n",
      "   macro avg       0.37      0.50      0.43      2196\n",
      "weighted avg       0.56      0.75      0.64      2196\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/keshu/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "check_sklearn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
